---
date: 2020-03-07
title: "Project 1: SNV detection using the BWT"
---

**Due: Mon March 30, 2020**  
**Posted: March 9, 2020**  
**ZZZ**  

**Note**: This assignment is based on a project developed by HÃ©ctor Corrada Bravo for a previous 
iteration of the course.  However, it has been modified (in parts, substantially) for the current iteration of the course.

You will implement approximate string matching using a seed-and-check / seed-and-extend strategy based on exact matching using the
Burrows-Wheeler transform. 

We are providing starter code to get you going. Instructions on implementation and code are here:

[https://gitlab.umiacs.umd.edu/hcorrada/cmsc423_project4](https://gitlab.umiacs.umd.edu/hcorrada/cmsc423_project4)

I **highly, highly** recommend that you use [`git`](https://git-scm.com/book/en/v1/Getting-Started) for developing your code.

To get code you will be using for this project using git:

~~~bash
git clone https://gitlab.umiacs.umd.edu/hcorrada/cmsc423_project4.git
~~~

This will create a `project4` directory with all code and data required for this project.

## Programming Questions ##

Instructions on how to prepare your solution are given in
[project code repository](https://gitlab.umiacs.umd.edu/hcorrada/cmsc423_project4).

## Assignment ##

The goal of this project is to build a _very, very basic_ read aligner with the purpose of using it to discover variants 
in a genome.  

### The problem of variant finding ###

The problem of using a sequenced sample to determine genomic variants with respect to some reference genome is common.  In reality, there are entire _pipelines_ focused around the challenges posed by variant detection from experimental data.  One of the big challenges includes potentially low sequencing coverage of the variant regions, which makes it difficult to distinguish a true variant from sequencing errors.

However, for the purposes of this assignment, our focus is on implementing the concepts we've built up in class, and so we've made the actual variant detection problem easy by (1) providing _very high_ coverage of the target genome so that the detection of variants is easier (2) limiting the size of variants to be very small, which makes them easier to detect and (3) giving you extra information (the number of variants).

The basic variant detection procedure is as follows.  You will build a tool to align your reads to the reference genome.  Then, by looking at "pile ups" of the reads on the reference genome, you will determine places where the sequenced sample (represented in the simulated reads) differs from the reference data, as evidenced by the repeated variation in the reads that cover a certain position in the genome.

### Your data ###

You are provided with a _reference genome_ for a particular strain of the coronavirus (2019-nCoV/USA-IL1/2020).
This genome is a single "contig" (a single fasta file entry) and is provided in `data/2019-nCoV.fa`.  *NOTE*: This is the _real_ sequence for this strain of the coronavirus (cool, huh?).

Additionally, you are provided with a set of _single-end_ sequencing reads.  There are 1,000,000 reads, each of length 100 nucleotides / base pairs (100bp).  They have been simulated from a _variant strain_ of the coronavirus that has a small number of variations (both point mutations and small insertions and deletions) with respect to the reference strain provided in `data/2019-nCoV.fa`.

### Your goal ###

**Your task is to write a basic read alignment tool, based on the seed-and-extend or seed-and-vote paradigm (whichever you prefer) using the FM-index for efficient seed finding**.

Your tool should have 

Simplifications for the data provided in this project:

  * Often, reads will be drawn (approximately equally) from both the forward and reverse complement strands of
  the underlying (c)DNA.  However, to simplify the read alignment problem for this project, the reads are 
  _all drawn from the forward strand_.  That means that instead of having to consider aligning both the provided 
  sequence of each read as well as that read's reverse complement (or, instead of having to index both the index
  and the reverse complement of the index), you can simply index the reference in the provided orientation and 
  you can assume that each read will align in its provided orientation.


**Question**. The provided reads are drawn from a strain of the coronavirus; your goal is to determine _what variants_ this strain has with respect to the reference genome with which you are provided (in `data/2019-nCoV.fa`).

**How to look for variants:** To look for variants, I _highly_ suggest you use the Integrative Genomics Viewer (IGV), which you can get for all platforms [here](https://software.broadinstitute.org/software/igv/download).  This is a tool to let you visualize the pileup of alignments on the genome and determine what the relevant variants are.  To load the SAM file generated by your program into IGV, you first need to sort and index the file.  The easiest way to do this is with [samtools](http://www.htslib.org/download/).

The easiest way to do this is to install [samtools](http://www.htslib.org).  If you don't want to compile these from source, you can install it using the [bioconda package manager](https://bioconda.github.io), which will acquire a pre-compiled binary for you.  Once you have samtools installed, you can convert your SAM file to a BAM file (a compressed, binary version of the SAM file that is commonly used in bioinformatics tools) using the following command:

~~~bash
$ samtools view -b -o mapping.bam mapping.sam
~~~

Now, you have a BAM file of your alignments.  The next task is to sort the alignments by coordinate, which can be completed
with the following command:

~~~bash
$ samtools sort -o mapping_sorted.bam mapping.bam
~~~

Finally, you can generate the index used by IGV with:

~~~bash
$ samtools index mapping_sorted.bam
~~~

As an alternative to samtools, the above can also be done with the Picard tools (written in Java), which is available [here](https://broadinstitute.github.io/picard/), though the exact syntax and command names are slightly different.

Now, you have both the original genome `2019-nCoV.fa` and the sorted BAM file with your alignments `mapping_sorted.bam`. 
Open up IGV, and load the genome.  You can do this through the main menu by *Genomes* -> *Load Genome From File*, and pointing it at `2019-nCoV.fa`.  Then, you can load your alignments using *File* -> *Load from File*, and pointing it at `mapping_sorted.bam`.  IGV will load the file and you can now explore the visualization.  Detailed instructions on how to navigate your alignments using IGV can be found [here](https://software.broadinstitute.org/software/igv/AlignmentData).  **You can use IGV to interactively navigate the pileup and locate the variants**.

## Deliverables ##

Your deliverable consists of a tarball containing:

 1. Your source code, along with a README.md file containing instructions for building your tool.  If your tool is written in a compiled language (C/C++, Java, Rust, Go, etc.), then it should build using a single command using the canonical build system for the language (e.g. `make` for C/C++, `cargo` for Rust, etc.).
 
 2. A report, in PDF format, that is a writeup discussing your findings.  Specifically, your report
    should contain _at least_ the following sections:
    
      * Discovered variants : what variants did you discover?  What is the evidence you found for these 
      variants?  You are encouraged to include e.g. screenshots from IGV showing your pileups in the variant regions.
      
      * Design : what specific design decisions did you make in your tool, and why?  If you were going to start the 
        project again from scratch, what, if anything, would you do differently?
      
      * Roadblocks : what part of the project did you find the most difficult?  Where did you get stuck and how did you 	(hopefully) overcome this difficulty?

### Notes:

1. You may use an existing library to help with the parsing of the input.  Very simple functions to read FASTA and FASTQ files in a few different languages can be found [here](https://github.com/lh3/readfq).  If you have a question about whether or not you can use a specific library, just ask.  The requirements for this project are _much less strict_ than for Project      Rosalind.  Unless the library performs one of the core functions we want you to implement, we are likely to say "yes" to it.
   
2. The `pileup.py` script in the project repository can help you answer this question. 
You can get a list of mismatches found in reads, and the number of times each kind of mismatch is observed in each position as follows:


~~~python
from pileup import PileUp
from approximate_matcher import ApproximateMatcher

# initialize object
am = ApproximateMatcher(reference)
pileup = PileUp(reference)
d = 3

for read in reads:
	# find approximate matching positions for a given read
	# assumes positions is a list (even if only a single match is found)
	# with matching positions
	positions = am.get_matches(read, d)
	if len(positions) > 0:
		# add to pileup object
		pileup.insert(positions, read)

# next statement prints out mismatching positions
# output is:
# (<position>, <reference_character>, [(<variant_character>,
# <num_times_aligned>)])
# argument filters mismatch by frequency in which variant character
# is observed, e.g., .01 means variant character has to be seen at least
# once for every 100 aligned nucleotides
pileup.print_mismatches(.01)
~~~

where positions are indices in the reference string where an approximate match for `read` was found.

## How to submit ##

On ELMS you will submit two things

(1) A `diff` of your solution and the original code posted by us. Using git you can do this as follows
once you have committed all your code changes in directory `approximate_matcher`. Note that you do not need to change code outside of this directory to solve the Rosalind problem:

~~~bash
git diff origin/master approximate_matcher > project4_bwt_code.patch
~~~

Submit file `project4_bwt_code.patch` on ELMS

(2) An IPython notebook exported as pdf or html containing your answer to Question 1 above along with code used to answer it. You have to use your approximate matching code from part I to match reads to the reference, otherwise, you are free to use Biopython as needed to answer this question. E.g., to do DNA->aminoacid translation.
